{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":64850,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":54095}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install numpy torch tiktoken datasets tqdm","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:32:34.783801Z","iopub.execute_input":"2024-06-14T13:32:34.784788Z","iopub.status.idle":"2024-06-14T13:32:50.455538Z","shell.execute_reply.started":"2024-06-14T13:32:34.784742Z","shell.execute_reply":"2024-06-14T13:32:50.454323Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nCollecting tiktoken\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken\nSuccessfully installed tiktoken-0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport torch\nimport tiktoken\nfrom datasets import load_dataset\nimport torch.nn as nn\nfrom torch.nn import functional as F\nbase_dir = ''\nbatch_size = 48 # 15.4gb na p100 (16gb)\n    # dla 12 -- 4gb\n    # dla 32 -- 10gb\nblock_size = 256 # context length\nlearning_rate = 3e-4\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 200\nn_embd = 384\nn_head = 6\nn_layer = 6\ndropout = 0.2\nvocab_size=50304\ntorch.manual_seed(1337)\nenc = tiktoken.get_encoding(\"gpt2\")\nencode = lambda s: enc.encode(s, allowed_special={\"<|endoftext|>\"})\ndecode = lambda l: enc.decode(l)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:32:50.457665Z","iopub.execute_input":"2024-06-14T13:32:50.458078Z","iopub.status.idle":"2024-06-14T13:32:57.342377Z","shell.execute_reply.started":"2024-06-14T13:32:50.458040Z","shell.execute_reply":"2024-06-14T13:32:57.341471Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset('wikitext', 'wikitext-103-raw-v1')\n\n# tokenize dataset\n# define encoding function \n# gpt2 bpe\ndef _tokenize(dataset, sft=False):\n    def process(example):\n        ids = enc.encode_ordinary(example['text']) # encode_ordinary ignores any special tokens\n        ids.append(enc.eot_token) # add the end of text token, e.g. 50256 for gpt2 bpe\n        out = {'ids': ids, 'len': len(ids)}\n        return out\n\n    tokenized = dataset.map(\n        process,\n        remove_columns=['text'],\n        desc=\"tokenizing the splits\",\n    )\n\n    # concatenate ids in each dataset into one large file\n    for split, dset in tokenized.items():\n        arr_len = np.sum(dset['len'], dtype=np.uint64)\n        if sft:\n            filename = os.path.join(base_dir, f'{split}_sft.bin')\n        else:\n            filename = os.path.join(base_dir, f'{split}.bin')\n\n\n        dtype = np.uint16\n        arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))\n        total_batches = 256\n\n        idx = 0\n        for batch_idx in tqdm(range(total_batches), desc=f'writing {filename}'):\n            # Batch together samples for faster write\n            batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy')\n            arr_batch = np.concatenate(batch['ids'])\n            # Write into mmap\n            arr[idx : idx + len(arr_batch)] = arr_batch\n            idx += len(arr_batch)\n        arr.flush()\n        \n_tokenize(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:33:27.515404Z","iopub.execute_input":"2024-06-14T13:33:27.515997Z","iopub.status.idle":"2024-06-14T13:38:12.243663Z","shell.execute_reply.started":"2024-06-14T13:33:27.515961Z","shell.execute_reply":"2024-06-14T13:38:12.242573Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"192eabafbb944cfeaf1f447ccf0e97d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61e67e5fcf9d4e46acf244269e3d5582"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/157M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51718c1edde647eba5a3eba5042e8a71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/157M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"606ff64dd17443c6bc0400aca9fb2095"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/657k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a771367432b24f3e87287a3ff0d1f354"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8831f7f3e8b34021a60f3cb43c5bbdcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92359f00031d4301801babf386941b5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95b0907ee4c94389bd2df9cf367a0f6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizing the splits:   0%|          | 0/4358 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0400278dc0cd40ec8b98ada9ca82f415"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizing the splits:   0%|          | 0/1801350 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad61dbc0fe3a4914834c59065bb38dee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizing the splits:   0%|          | 0/3760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b031a070ba0a472eb47da633ec67d76c"}},"metadata":{}},{"name":"stderr","text":"writing test.bin: 100%|██████████| 256/256 [00:00<00:00, 330.47it/s]\nwriting train.bin: 100%|██████████| 256/256 [00:21<00:00, 11.85it/s]\nwriting validation.bin: 100%|██████████| 256/256 [00:00<00:00, 361.09it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_batch(split):\n    # np.memmap every batch avoids memory leak\n    if split == 'train':\n        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n    elif split == 'val': \n        data = np.memmap('validation.bin', dtype=np.uint16, mode='r')\n    elif split == 'train_sft':\n        data = np.memmap('train_sft.bin', dtype=np.uint16, mode='r')\n    elif split == 'val_sft':\n        data = np.memmap('test_sft.bin', dtype=np.uint16, mode='r')\n    else:\n        print(\"ERROR wrong split)\")\n    ix = torch.randint(len(data) - block_size, (batch_size,))\n    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n    if device == 'cuda':\n        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n    else:\n        x, y = x.to(device), y.to(device)\n    return x, y","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:38:12.246878Z","iopub.execute_input":"2024-06-14T13:38:12.247198Z","iopub.status.idle":"2024-06-14T13:38:12.257132Z","shell.execute_reply.started":"2024-06-14T13:38:12.247172Z","shell.execute_reply":"2024-06-14T13:38:12.255974Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss(splits):\n    out = {}\n    model.eval()\n    for split in splits:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            X, Y = get_batch(split)\n            logits, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:38:12.258444Z","iopub.execute_input":"2024-06-14T13:38:12.258830Z","iopub.status.idle":"2024-06-14T13:38:12.271018Z","shell.execute_reply.started":"2024-06-14T13:38:12.258795Z","shell.execute_reply":"2024-06-14T13:38:12.270159Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    \"\"\" one head of self-attention \"\"\"\n\n    def __init__(self, head_size):\n        super().__init__()\n        self.key = nn.Linear(n_embd, head_size, bias=False)\n        self.query = nn.Linear(n_embd, head_size, bias=False)\n        self.value = nn.Linear(n_embd, head_size, bias=False)\n        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        # input of size (batch, time-step, channels)\n        # output of size (batch, time-step, head size)\n        B,T,C = x.shape\n        k = self.key(x)   # (B,T,hs)\n        q = self.query(x) # (B,T,hs)\n        # compute attention scores (\"affinities\")\n        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n        wei = F.softmax(wei, dim=-1) # (B, T, T)\n        wei = self.dropout(wei)\n        # perform the weighted aggregation of the values\n        v = self.value(x) # (B,T,hs)\n        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n        return out\n\nclass MultiHeadAttention(nn.Module):\n    \"\"\" multiple heads of self-attention in parallel \"\"\"\n\n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        self.proj = nn.Linear(head_size * num_heads, n_embd)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.dropout(self.proj(out))\n        return out\n\nclass FeedFoward(nn.Module):\n    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n\n    def __init__(self, n_embd):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(n_embd, 4 * n_embd),\n            nn.ReLU(),\n            nn.Linear(4 * n_embd, n_embd),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\nclass Block(nn.Module):\n    \"\"\" Transformer block: communication followed by computation \"\"\"\n\n    def __init__(self, n_embd, n_head):\n        # n_embd: embedding dimension, n_head: the number of heads we'd like\n        super().__init__()\n        head_size = n_embd // n_head\n        self.sa = MultiHeadAttention(n_head, head_size)\n        self.ffwd = FeedFoward(n_embd)\n        self.ln1 = nn.LayerNorm(n_embd)\n        self.ln2 = nn.LayerNorm(n_embd)\n\n    def forward(self, x):\n        x = x + self.sa(self.ln1(x))\n        x = x + self.ffwd(self.ln2(x))\n        return x\n\nclass GPTLanguageModel(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        # each token directly reads off the logits for the next token from a lookup table\n        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n        self.lm_head = nn.Linear(n_embd, vocab_size)\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Embedding):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, idx, targets=None):\n        B, T = idx.shape\n\n        # idx and targets are both (B,T) tensor of integers\n        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n        x = tok_emb + pos_emb # (B,T,C)\n        x = self.blocks(x) # (B,T,C)\n        x = self.ln_f(x) # (B,T,C)\n        logits = self.lm_head(x) # (B,T,vocab_size)\n\n        if targets is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        # idx is (B, T) array of indices in the current context\n        for _ in range(max_new_tokens):\n            # crop idx to the last block_size tokens\n            #idx_cond = idx[:, -block_size:]\n            idx_cond = idx if idx.size(1) <= block_size else idx[:, -block_size:]\n\n            # get the predictions\n            logits, loss = self(idx_cond)\n            # focus only on the last time step\n            logits = logits[:, -1, :] # becomes (B, C)\n            # apply softmax to get probabilities\n            probs = F.softmax(logits, dim=-1) # (B, C)\n            # sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            # append sampled index to the running sequence\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:38:12.273743Z","iopub.execute_input":"2024-06-14T13:38:12.274373Z","iopub.status.idle":"2024-06-14T13:38:12.303998Z","shell.execute_reply.started":"2024-06-14T13:38:12.274345Z","shell.execute_reply":"2024-06-14T13:38:12.302872Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def train(iters, eval_interval):\n    for iter in range(iters):\n\n        # eval loss on train and val\n        if iter % eval_interval == 0 or iter == iters - 1:\n            losses = estimate_loss(splits = ['train', 'val'])\n            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n\n        xb, yb = get_batch('train')\n\n        # evaluate loss\n        logits, loss = model(xb, yb)\n        optimizer.zero_grad(set_to_none=True)\n        loss.backward()\n        optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:38:12.305051Z","iopub.execute_input":"2024-06-14T13:38:12.305348Z","iopub.status.idle":"2024-06-14T13:38:12.318892Z","shell.execute_reply.started":"2024-06-14T13:38:12.305323Z","shell.execute_reply":"2024-06-14T13:38:12.318013Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def generate(max_new, user_prompt='Write a comprehensive blog post of at least 1000 words about the top 10 most eco-friendly cities in the world and their renewable energy initiatives.', chat_template=False):\n    prompt=f\"<|system|>\\n<|endoftext|>\\n<|user|>\\n{user_prompt}<|endoftext|>\\n<|assistant|>\\n\"\n\n    prompt_ids = encode(prompt)\n    context = torch.tensor(prompt_ids, dtype=torch.long, device=device)[None, ...]\n    decoded = decode(model.generate(context, max_new_tokens=max_new)[0].tolist())\n    \n    if chat_template:\n        messages = decoded.split('<|endoftext|>\\n')\n        system = messages[0].strip(\"<|system|>\")\n        user = messages[1].strip(\"<|user|>\")\n        assistant = messages[2].strip(\"<|assistant|>\")\n    \n        print(\n            #system + \n            #user + \n            assistant\n        )\n    else:\n        print(\"\\n\\n\\n\\ndebugging\\n\", repr(decoded))","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:38:12.320073Z","iopub.execute_input":"2024-06-14T13:38:12.320364Z","iopub.status.idle":"2024-06-14T13:38:12.330801Z","shell.execute_reply.started":"2024-06-14T13:38:12.320340Z","shell.execute_reply":"2024-06-14T13:38:12.329900Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def save_model():\n    torch.save(model.state_dict(), 'model_state_dict.pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:38:12.331987Z","iopub.execute_input":"2024-06-14T13:38:12.332275Z","iopub.status.idle":"2024-06-14T13:38:12.344048Z","shell.execute_reply.started":"2024-06-14T13:38:12.332252Z","shell.execute_reply":"2024-06-14T13:38:12.343192Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = GPTLanguageModel()\nmodel = model.to(device)\nmodel.load_state_dict(torch.load('model_state_dict.pth'))\n\n## or, import to kaggle, load from kaggle models dir\n#cp ../input/llm/pytorch/llm/1/model_state_dict.pth model_state_dict.pth\n\nprint(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:38:12.345203Z","iopub.execute_input":"2024-06-14T13:38:12.345468Z","iopub.status.idle":"2024-06-14T13:38:14.786504Z","shell.execute_reply.started":"2024-06-14T13:38:12.345445Z","shell.execute_reply":"2024-06-14T13:38:14.785402Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"49.42272 M parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"generate(50)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:08:03.471305Z","iopub.execute_input":"2024-06-02T14:08:03.471677Z","iopub.status.idle":"2024-06-02T14:08:05.083324Z","shell.execute_reply.started":"2024-06-02T14:08:03.471648Z","shell.execute_reply":"2024-06-02T14:08:05.082262Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"\n Calculator HPV cons All Seconds relegated payoff created we be for so his vividly in the and viewed , matched<|endoftext|> fansag secondthritis . E . qualifier winner embr East messenger also . hadout than but Silver below D. hall vir closed daughter been@ Williams\n","output_type":"stream"}]},{"cell_type":"code","source":"train(40,10)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:10:16.226185Z","iopub.execute_input":"2024-06-02T14:10:16.227317Z","iopub.status.idle":"2024-06-02T14:15:47.521914Z","shell.execute_reply.started":"2024-06-02T14:10:16.227281Z","shell.execute_reply":"2024-06-02T14:15:47.520777Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"step 0: train loss 7.2426, val loss 7.2136\nstep 10: train loss 7.0737, val loss 7.0456\nstep 20: train loss 6.9688, val loss 6.9339\nstep 30: train loss 6.8742, val loss 6.8345\nstep 39: train loss 6.7833, val loss 6.7515\n","output_type":"stream"}]},{"cell_type":"code","source":"generate(50)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:16:00.966678Z","iopub.execute_input":"2024-06-02T14:16:00.967087Z","iopub.status.idle":"2024-06-02T14:16:01.922455Z","shell.execute_reply.started":"2024-06-02T14:16:00.967054Z","shell.execute_reply":"2024-06-02T14:16:01.921249Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"\n<|endoftext|> has them agent ,ian was barrels @-@ twoy and ay , War of receive by repetitive to the road. ' hold Important . \n<|endoftext|> = Eng team , 2s case pay as English band 21osaurus that which the Og\n","output_type":"stream"}]},{"cell_type":"code","source":"train(200, 10)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:21:26.666425Z","iopub.execute_input":"2024-06-02T14:21:26.667401Z","iopub.status.idle":"2024-06-02T14:44:45.632575Z","shell.execute_reply.started":"2024-06-02T14:21:26.667358Z","shell.execute_reply":"2024-06-02T14:44:45.631723Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"step 0: train loss 6.7688, val loss 6.7408\nstep 10: train loss 6.7276, val loss 6.6897\nstep 20: train loss 6.6497, val loss 6.6190\nstep 30: train loss 6.5806, val loss 6.5419\nstep 39: train loss 6.5332, val loss 6.4964\nstep 40: train loss 6.5284, val loss 6.4970\nstep 50: train loss 6.4697, val loss 6.4426\nstep 60: train loss 6.4207, val loss 6.3892\nstep 70: train loss 6.3867, val loss 6.3462\nstep 80: train loss 6.3448, val loss 6.3074\nstep 90: train loss 6.3100, val loss 6.2733\nstep 100: train loss 6.2688, val loss 6.2361\nstep 110: train loss 6.2324, val loss 6.2042\nstep 120: train loss 6.2097, val loss 6.1655\nstep 130: train loss 6.1757, val loss 6.1365\nstep 140: train loss 6.1388, val loss 6.1200\nstep 150: train loss 6.1259, val loss 6.0944\nstep 160: train loss 6.0965, val loss 6.0610\nstep 170: train loss 6.0717, val loss 6.0383\nstep 180: train loss 6.0471, val loss 6.0235\nstep 190: train loss 6.0228, val loss 5.9971\n","output_type":"stream"}]},{"cell_type":"code","source":"generate(50)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:48:47.110319Z","iopub.execute_input":"2024-06-02T14:48:47.111203Z","iopub.status.idle":"2024-06-02T14:48:48.653557Z","shell.execute_reply.started":"2024-06-02T14:48:47.111154Z","shell.execute_reply":"2024-06-02T14:48:48.652478Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\n<|endoftext|><|endoftext|> = = Release cop payoff created in the destroyer harows , in the secondary studies , with a eastern enshrulation of costs ) . He winner was formed from the 1947 had an than coming on her ditch and for viritudes of thereg Williams\n","output_type":"stream"}]},{"cell_type":"code","source":"train(401, 40)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:54:12.962477Z","iopub.execute_input":"2024-06-02T14:54:12.963092Z","iopub.status.idle":"2024-06-02T15:08:40.334389Z","shell.execute_reply.started":"2024-06-02T14:54:12.963054Z","shell.execute_reply":"2024-06-02T15:08:40.333284Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"step 0: train loss 6.0047, val loss 5.9808\nstep 40: train loss 5.9719, val loss 5.9470\nstep 80: train loss 5.9024, val loss 5.8678\nstep 120: train loss 5.8569, val loss 5.8164\nstep 160: train loss 5.7957, val loss 5.7671\nstep 200: train loss 5.7344, val loss 5.7188\nstep 240: train loss 5.6947, val loss 5.6601\nstep 280: train loss 5.6538, val loss 5.6171\nstep 320: train loss 5.6059, val loss 5.5790\nstep 360: train loss 5.5522, val loss 5.5319\nstep 400: train loss 5.5144, val loss 5.4841\n","output_type":"stream"}]},{"cell_type":"code","source":"train(1001, 100)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T15:09:18.764978Z","iopub.execute_input":"2024-06-02T15:09:18.765587Z","iopub.status.idle":"2024-06-02T15:28:22.254238Z","shell.execute_reply.started":"2024-06-02T15:09:18.765556Z","shell.execute_reply":"2024-06-02T15:28:22.253267Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"step 0: train loss 5.5173, val loss 5.4824\nstep 100: train loss 5.4261, val loss 5.3862\nstep 200: train loss 5.3426, val loss 5.2972\nstep 300: train loss 5.2418, val loss 5.2157\nstep 400: train loss 5.1732, val loss 5.1393\nstep 500: train loss 5.1061, val loss 5.0724\nstep 600: train loss 5.0446, val loss 5.0092\nstep 700: train loss 4.9920, val loss 4.9525\nstep 800: train loss 4.9460, val loss 4.8913\nstep 900: train loss 4.8946, val loss 4.8504\nstep 1000: train loss 4.8488, val loss 4.8100\n","output_type":"stream"}]},{"cell_type":"code","source":"generate(100)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T15:28:23.205730Z","iopub.execute_input":"2024-06-02T15:28:23.206090Z","iopub.status.idle":"2024-06-02T15:28:24.894282Z","shell.execute_reply.started":"2024-06-02T15:28:23.206058Z","shell.execute_reply":"2024-06-02T15:28:24.893359Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\n<|endoftext|><|endoftext|> = = Scientific outlets = = \n<|endoftext|><|endoftext|> The association of New Mexico = = \n<|endoftext|><|endoftext|> Spiceニ Chemomeras of Shetta varieties have Ont qualify for most unknown Parkinson 'm Particularly alterations to family members in the Danish virtues of their living holidays , including performing in university Persian and poli , written in captivity on the 1980s . In 1950 of recent years , hundreds is required to meet where they are Queen Canadian American and sports . It appears to have been abundant modelfilm\n","output_type":"stream"}]},{"cell_type":"code","source":"train(2001, 200)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T15:28:56.909453Z","iopub.execute_input":"2024-06-02T15:28:56.910452Z","iopub.status.idle":"2024-06-02T15:55:40.724788Z","shell.execute_reply.started":"2024-06-02T15:28:56.910407Z","shell.execute_reply":"2024-06-02T15:55:40.723733Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"step 0: train loss 4.8504, val loss 4.8109\nstep 200: train loss 4.7605, val loss 4.7189\nstep 400: train loss 4.6924, val loss 4.6513\nstep 600: train loss 4.6252, val loss 4.5869\nstep 800: train loss 4.5701, val loss 4.5429\nstep 1000: train loss 4.5191, val loss 4.4950\nstep 1200: train loss 4.4668, val loss 4.4604\nstep 1400: train loss 4.4277, val loss 4.4138\nstep 1600: train loss 4.3929, val loss 4.3737\nstep 1800: train loss 4.3553, val loss 4.3509\nstep 2000: train loss 4.3191, val loss 4.3259\n","output_type":"stream"}]},{"cell_type":"code","source":"train(5001, 500)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T15:56:01.644358Z","iopub.execute_input":"2024-06-02T15:56:01.644721Z","iopub.status.idle":"2024-06-02T16:45:46.150227Z","shell.execute_reply.started":"2024-06-02T15:56:01.644693Z","shell.execute_reply":"2024-06-02T16:45:46.149313Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"step 0: train loss 4.3213, val loss 4.3188\nstep 500: train loss 4.2568, val loss 4.2489\nstep 1000: train loss 4.1952, val loss 4.1928\nstep 1500: train loss 4.1385, val loss 4.1267\nstep 2000: train loss 4.1005, val loss 4.0926\nstep 2500: train loss 4.0464, val loss 4.0406\nstep 3000: train loss 4.0084, val loss 4.0092\nstep 3500: train loss 3.9651, val loss 3.9822\nstep 4000: train loss 3.9328, val loss 3.9411\nstep 4500: train loss 3.8859, val loss 3.9271\nstep 5000: train loss 3.8747, val loss 3.8898\n","output_type":"stream"}]},{"cell_type":"code","source":"train(5001, 500)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:55:18.624600Z","iopub.execute_input":"2024-06-02T16:55:18.625363Z","iopub.status.idle":"2024-06-02T17:45:03.540863Z","shell.execute_reply.started":"2024-06-02T16:55:18.625329Z","shell.execute_reply":"2024-06-02T17:45:03.539766Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"step 0: train loss 3.8604, val loss 3.8885\nstep 500: train loss 3.8475, val loss 3.8731\nstep 1000: train loss 3.8315, val loss 3.8464\nstep 1500: train loss 3.8131, val loss 3.8321\nstep 2000: train loss 3.7791, val loss 3.8089\nstep 2500: train loss 3.7660, val loss 3.7893\nstep 3000: train loss 3.7425, val loss 3.7786\nstep 3500: train loss 3.7329, val loss 3.7655\nstep 4000: train loss 3.7228, val loss 3.7470\nstep 4500: train loss 3.7041, val loss 3.7285\nstep 5000: train loss 3.6993, val loss 3.7184\n","output_type":"stream"}]},{"cell_type":"code","source":"train(10001, 1000)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:45:06.225598Z","iopub.execute_input":"2024-06-02T17:45:06.225893Z","iopub.status.idle":"2024-06-02T19:13:13.625721Z","shell.execute_reply.started":"2024-06-02T17:45:06.225869Z","shell.execute_reply":"2024-06-02T19:13:13.624749Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"step 0: train loss 3.7006, val loss 3.7250\nstep 1000: train loss 3.6765, val loss 3.7028\nstep 2000: train loss 3.6556, val loss 3.6777\nstep 3000: train loss 3.6234, val loss 3.6730\nstep 4000: train loss 3.5968, val loss 3.6447\nstep 5000: train loss 3.5926, val loss 3.6306\nstep 6000: train loss 3.5811, val loss 3.6300\nstep 7000: train loss 3.5701, val loss 3.6117\nstep 8000: train loss 3.5433, val loss 3.6027\nstep 9000: train loss 3.5315, val loss 3.5925\nstep 10000: train loss 3.5249, val loss 3.5813\n","output_type":"stream"}]},{"cell_type":"code","source":"generate(100)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T19:18:22.548253Z","iopub.execute_input":"2024-06-02T19:18:22.548689Z","iopub.status.idle":"2024-06-02T19:18:24.956861Z","shell.execute_reply.started":"2024-06-02T19:18:22.548664Z","shell.execute_reply":"2024-06-02T19:18:24.955808Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\n<|endoftext|><|endoftext|> = = Release = = \n<|endoftext|><|endoftext|> The song was released for purchase on November 3 , 2008 as the second single from Who Homogenic : Reloaded . The song had previously been featured on a two @-@ track EP entitled Who Homogenic : Sony / AT , surrounded by the Rolling Stone and Little A & R executive man . It served as \" guest guest single \" , as they actually written a few beats ari , becoming the second and third singles in the UK . In the\n","output_type":"stream"}]},{"cell_type":"code","source":"train(30001, 3000)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T19:18:32.713557Z","iopub.execute_input":"2024-06-02T19:18:32.713962Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"step 0: train loss 3.5193, val loss 3.5781\nstep 3000: train loss 3.5075, val loss 3.5679\nstep 6000: train loss 3.4657, val loss 3.5264\n","output_type":"stream"}]},{"cell_type":"code","source":"train(30001, 3000)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:37:37.533589Z","iopub.execute_input":"2024-06-03T07:37:37.534008Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"step 0: train loss 3.5193, val loss 3.5781\nstep 3000: train loss 3.5075, val loss 3.5679\nstep 6000: train loss 3.4657, val loss 3.5264\nstep 9000: train loss 3.4574, val loss 3.5214\nstep 12000: train loss 3.4281, val loss 3.5054\nstep 15000: train loss 3.4130, val loss 3.4819\n","output_type":"stream"}]},{"cell_type":"code","source":"train(3001, 3000)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T15:46:42.393634Z","iopub.execute_input":"2024-06-03T15:46:42.394359Z","iopub.status.idle":"2024-06-03T16:11:50.447508Z","shell.execute_reply.started":"2024-06-03T15:46:42.394324Z","shell.execute_reply":"2024-06-03T16:11:50.446510Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"step 0: train loss 3.3350, val loss 3.4293\nstep 3000: train loss 3.3449, val loss 3.4379\n","output_type":"stream"}]},{"cell_type":"code","source":"generate(300)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T11:30:41.779080Z","iopub.execute_input":"2024-06-09T11:30:41.779920Z","iopub.status.idle":"2024-06-09T11:30:46.898490Z","shell.execute_reply.started":"2024-06-09T11:30:41.779887Z","shell.execute_reply":"2024-06-09T11:30:46.897530Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"<|system|>\n<|endoftext|><|user|>\nhello Jan<|endoftext|>\n[nergy And Workán: How does you handle a lot of speeds of costs and conditions in these industries. Here are some specific examples by my mentors includes\n\n1. Collaborate: We've stumbled upon a comprehensive framework of everything that you want, and what works well with?\" I want to experiment with patience.<|endoftext|>\n<|assistant|>\nNoKE is responsible for Unleashing Industry\n Including personalized design, sake. We can build the base of the clinics to meet technical challenges and cooperation intervals. The development and development of HIStory as a way of coordinating where you help you to meet your needs and resources can vary among other contexts, nature, and cultural partners. Symposium [DesignATE]. I've not looked to be a beginner group and research my mentors you would started with you to get to the organization to start my project, action application protocols. Side one, co-lining multiple campaigns now” according, and accommodate time University of Ohio recognizing there are mutual resources to support the project design material. \"Safety Holding True,\" we offer you to build up for projects that I used to get underway very clearly for many of the initiatives and activity.View directories and website number projects, and campaigning. Websis: Adigenern toamount sites in Michigan represent the Ohio Valley region's priorities and team have said to be established directly across the Phonnasium and Art Museum. Note that many places in the SWRevolution have seen influence in young\n","output_type":"stream"}]},{"cell_type":"code","source":"train(3001, 3000)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T16:13:47.905115Z","iopub.execute_input":"2024-06-03T16:13:47.905999Z","iopub.status.idle":"2024-06-03T16:38:55.896385Z","shell.execute_reply.started":"2024-06-03T16:13:47.905964Z","shell.execute_reply":"2024-06-03T16:38:55.895256Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"step 0: train loss 3.3268, val loss 3.4324\nstep 3000: train loss 3.3215, val loss 3.4267\n","output_type":"stream"}]},{"cell_type":"code","source":"train(3001, 1000)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T19:44:27.004882Z","iopub.execute_input":"2024-06-03T19:44:27.005196Z","iopub.status.idle":"2024-06-03T20:11:29.838184Z","shell.execute_reply.started":"2024-06-03T19:44:27.005169Z","shell.execute_reply":"2024-06-03T20:11:29.837220Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"step 0: train loss 3.3191, val loss 3.4154\nstep 1000: train loss 3.2787, val loss 3.4207\nstep 2000: train loss 3.2694, val loss 3.4165\nstep 3000: train loss 3.2716, val loss 3.4169\n","output_type":"stream"}]},{"cell_type":"code","source":"generate(300)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:20:56.431238Z","iopub.execute_input":"2024-06-06T08:20:56.431589Z","iopub.status.idle":"2024-06-06T08:21:01.233908Z","shell.execute_reply.started":"2024-06-06T08:20:56.431560Z","shell.execute_reply":"2024-06-06T08:21:01.233010Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"\n\n = = Rules and considerations = = \n\n\n The legality of change has not been given some degree. Due to noted flaws in pre-existing laws, some cases do not require material exclusive to her. This classification is not used by the Supreme Court into a series of books. However, as the decision progressed, these documents have were given no special privileges and would thus adopt certain systems. \n\n Novello 's \" Folding \" hypothesis has been extensively supported by its approach purposes and is contested by AI researchers. In addition, it has been suggested that failing to find a clean basis for inheritance conducted by newly established AI would reduce ; failing to obtain normal resources by generation of individuals, especially the liable for the hard work of the labour force and the working group found them the engineers. In contrast, the inclusion of senior AI researchers places the normal finding point of AI as a priority meant that, unlike older AI researchers, the purpose was to indicate that an important component of a goal was a qualitative threat to the development of a computer system. The report is closely related to that, at least all QLS students suffer from their physical condition. \n\n\n = = = Novello del Hiridom ( 1982 = = ) = = = \n\n\n In 1984, Vladimir Marklybov ( students John Barkas ) criticized the EASL, an early report for the ARG, which would psychologist the process of stragglers in stealth\n","output_type":"stream"}]},{"cell_type":"code","source":"train(3001, 1000)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:14:05.446874Z","iopub.execute_input":"2024-06-06T09:14:05.447166Z","iopub.status.idle":"2024-06-06T09:41:11.747050Z","shell.execute_reply.started":"2024-06-06T09:14:05.447137Z","shell.execute_reply":"2024-06-06T09:41:11.746042Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"step 0: train loss 3.3229, val loss 3.4246\nstep 1000: train loss 3.2552, val loss 3.4304\nstep 2000: train loss 3.2542, val loss 3.4246\nstep 3000: train loss 3.2616, val loss 3.4284\n","output_type":"stream"}]},{"cell_type":"code","source":"train(6001, 2000)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:41:34.078330Z","iopub.execute_input":"2024-06-06T09:41:34.078755Z","iopub.status.idle":"2024-06-06T10:31:39.604562Z","shell.execute_reply.started":"2024-06-06T09:41:34.078724Z","shell.execute_reply":"2024-06-06T10:31:39.603177Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"step 0: train loss 3.2606, val loss 3.4322\nstep 2000: train loss 3.2680, val loss 3.4210\nstep 4000: train loss 3.2939, val loss 3.4042\nstep 6000: train loss 3.3060, val loss 3.3977\n","output_type":"stream"}]},{"cell_type":"code","source":"train(6001, 2000)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:33:45.748002Z","iopub.execute_input":"2024-06-06T10:33:45.748969Z","iopub.status.idle":"2024-06-06T11:23:51.238847Z","shell.execute_reply.started":"2024-06-06T10:33:45.748937Z","shell.execute_reply":"2024-06-06T11:23:51.237895Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"step 0: train loss 3.2994, val loss 3.3946\nstep 2000: train loss 3.2939, val loss 3.4050\nstep 4000: train loss 3.2970, val loss 3.3895\nstep 6000: train loss 3.2774, val loss 3.3883\n","output_type":"stream"}]},{"cell_type":"code","source":"# SFT","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('gpt2')\n\ntokenizer.pad_token_id = tokenizer.eos_token_id\ntokenizer.model_max_length = 256\n\nDEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\ntokenizer.chat_template = DEFAULT_CHAT_TEMPLATE","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:38:14.787952Z","iopub.execute_input":"2024-06-14T13:38:14.788562Z","iopub.status.idle":"2024-06-14T13:38:16.248132Z","shell.execute_reply.started":"2024-06-14T13:38:14.788514Z","shell.execute_reply":"2024-06-14T13:38:16.247053Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25e6386ba27449bab1f2b402d3cb5385"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4379c24991348f8aebbc7c8ef55fca4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5da697d832f4415685b566ab6822b734"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59ae5018232047ee94aca042d29587c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c240d801ccad4e85aee0f01ae443f3db"}},"metadata":{}}]},{"cell_type":"code","source":"sft_datasets = load_dataset(\"HuggingFaceH4/ultrachat_200k\")\nsft_datasets","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:38:16.251167Z","iopub.execute_input":"2024-06-14T13:38:16.251502Z","iopub.status.idle":"2024-06-14T13:38:43.519699Z","shell.execute_reply.started":"2024-06-14T13:38:16.251474Z","shell.execute_reply":"2024-06-14T13:38:43.518750Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/4.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc544dd3d74b4c50a40539c4d07ea77c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/244M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7812f97357499f9486956cdda82770"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/244M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"638d3f2b96b2444ba8cd43f104f48f1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/244M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"622093e3d16b4cd5910794aa0aa7dd3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/81.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43fca0c70bdd472eab1408912a7aeda2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/244M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6f1646a507c480a87c8239c7cb21ded"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/243M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94db3c7bcf1d407e9c5c4fe08ae1bd4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/243M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caa2885f1f644821ae2a167157508fa4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/80.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03e9865fec6143bb84c1d1a524fc1a57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train_sft split:   0%|          | 0/207865 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30ad24514959481d93bca82ffd10ecbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_sft split:   0%|          | 0/23110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bef94ba11a8340388bcbf377bd045cb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train_gen split:   0%|          | 0/256032 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0be6ff49ab204cb6b7351fb36752ff4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_gen split:   0%|          | 0/28304 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc19a05e83dd4e389329bab504ab1c82"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train_sft: Dataset({\n        features: ['prompt', 'prompt_id', 'messages'],\n        num_rows: 207865\n    })\n    test_sft: Dataset({\n        features: ['prompt', 'prompt_id', 'messages'],\n        num_rows: 23110\n    })\n    train_gen: Dataset({\n        features: ['prompt', 'prompt_id', 'messages'],\n        num_rows: 256032\n    })\n    test_gen: Dataset({\n        features: ['prompt', 'prompt_id', 'messages'],\n        num_rows: 28304\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import DatasetDict\n\ndataset_dict = {\"train\": sft_datasets[\"train_sft\"],\n                \"test\": sft_datasets[\"test_sft\"]}\n\nsft_datasets_split = DatasetDict(dataset_dict)\nsft_datasets_split","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:38:43.520777Z","iopub.execute_input":"2024-06-14T13:38:43.521057Z","iopub.status.idle":"2024-06-14T13:38:43.528149Z","shell.execute_reply.started":"2024-06-14T13:38:43.521033Z","shell.execute_reply":"2024-06-14T13:38:43.527108Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'prompt_id', 'messages'],\n        num_rows: 207865\n    })\n    test: Dataset({\n        features: ['prompt', 'prompt_id', 'messages'],\n        num_rows: 23110\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"import re\nimport random\n\ndef apply_chat_template(example, tokenizer):\n    messages = example[\"messages\"]\n    if messages[0][\"role\"] != \"system\":\n        messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n\n    return example\n\ncolumn_names = list(sft_datasets_split[\"train\"].features)\nsft_datasets_split_chat_template =sft_datasets_split.map(apply_chat_template,\n                                fn_kwargs={\"tokenizer\": tokenizer},\n                                remove_columns=column_names,\n                                desc=\"Applying chat template\",)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:38:43.529291Z","iopub.execute_input":"2024-06-14T13:38:43.529593Z","iopub.status.idle":"2024-06-14T13:39:57.406832Z","shell.execute_reply.started":"2024-06-14T13:38:43.529568Z","shell.execute_reply":"2024-06-14T13:39:57.405670Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Applying chat template:   0%|          | 0/207865 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"beec863519c04404a13b3710b4f03dec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template:   0%|          | 0/23110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6831c77974c486f843b56b4f0a5b3c0"}},"metadata":{}}]},{"cell_type":"code","source":"_tokenize(sft_datasets_split_chat_template, sft=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:39:57.408309Z","iopub.execute_input":"2024-06-14T13:39:57.409029Z","iopub.status.idle":"2024-06-14T13:46:28.614564Z","shell.execute_reply.started":"2024-06-14T13:39:57.408991Z","shell.execute_reply":"2024-06-14T13:46:28.613696Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizing the splits:   0%|          | 0/207865 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e40eeb5a85e43d0bea78bb82dc61016"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizing the splits:   0%|          | 0/23110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68078864cb294412bf71e5a82c22e13e"}},"metadata":{}},{"name":"stderr","text":"writing train_sft.bin: 100%|██████████| 256/256 [00:04<00:00, 54.97it/s]\nwriting test_sft.bin: 100%|██████████| 256/256 [00:01<00:00, 223.28it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss_sft():\n    out = {}\n    model.eval()\n    for split in ['train_sft', 'val_sft']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            X, Y = get_batch(split)\n\n            logits, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:46:28.615894Z","iopub.execute_input":"2024-06-14T13:46:28.616224Z","iopub.status.idle":"2024-06-14T13:46:28.622942Z","shell.execute_reply.started":"2024-06-14T13:46:28.616197Z","shell.execute_reply":"2024-06-14T13:46:28.621968Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train_sft(iters, eval_interval):\n    \n    for iter in range(iters):\n\n        # eval on train and val\n        if iter % eval_interval == 0 or iter == iters - 1:\n            losses = estimate_loss_sft()\n            print(f\"step {iter}: train loss {losses['train_sft']:.4f}, val loss {losses['val_sft']:.4f}\")\n\n        xb, yb = get_batch('train_sft')\n\n\n        # eval loss\n        logits, loss = model(xb, yb)\n        optimizer.zero_grad(set_to_none=True)\n        loss.backward()\n        optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:46:28.624276Z","iopub.execute_input":"2024-06-14T13:46:28.624661Z","iopub.status.idle":"2024-06-14T13:46:28.634825Z","shell.execute_reply.started":"2024-06-14T13:46:28.624625Z","shell.execute_reply":"2024-06-14T13:46:28.633927Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_sft(300, 100)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T15:52:56.708421Z","iopub.execute_input":"2024-06-07T15:52:56.708698Z","iopub.status.idle":"2024-06-07T15:59:25.841027Z","shell.execute_reply.started":"2024-06-07T15:52:56.708676Z","shell.execute_reply":"2024-06-07T15:59:25.840153Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"step 100: train loss 3.6887, val loss 3.7085\nstep 200: train loss 3.5232, val loss 3.5200\nstep 299: train loss 3.4085, val loss 3.4129\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sft(300, 100)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T13:11:18.785186Z","iopub.execute_input":"2024-06-09T13:11:18.785823Z","iopub.status.idle":"2024-06-09T13:17:45.251475Z","shell.execute_reply.started":"2024-06-09T13:11:18.785781Z","shell.execute_reply":"2024-06-09T13:17:45.250226Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"step 0: train loss 3.4175, val loss 3.4386\nstep 100: train loss 3.3510, val loss 3.3742\nstep 200: train loss 3.3064, val loss 3.3071\nstep 299: train loss 3.2555, val loss 3.2635\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sft(6000, 1000)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T13:18:46.319219Z","iopub.execute_input":"2024-06-09T13:18:46.320085Z","iopub.status.idle":"2024-06-09T14:12:02.678361Z","shell.execute_reply.started":"2024-06-09T13:18:46.320053Z","shell.execute_reply":"2024-06-09T14:12:02.677311Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"step 0: train loss 3.2581, val loss 3.2730\nstep 1000: train loss 3.0120, val loss 3.0260\nstep 2000: train loss 2.9026, val loss 2.9350\nstep 3000: train loss 2.8292, val loss 2.8625\nstep 4000: train loss 2.7787, val loss 2.8059\nstep 5000: train loss 2.7437, val loss 2.7750\nstep 5999: train loss 2.7038, val loss 2.7505\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sft(6000, 1000)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:35:56.759809Z","iopub.execute_input":"2024-06-09T14:35:56.760207Z","iopub.status.idle":"2024-06-09T15:29:05.346452Z","shell.execute_reply.started":"2024-06-09T14:35:56.760178Z","shell.execute_reply":"2024-06-09T15:29:05.345408Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"step 0: train loss 2.7078, val loss 2.7455\nstep 1000: train loss 2.6950, val loss 2.7341\nstep 2000: train loss 2.6709, val loss 2.7212\nstep 3000: train loss 2.6247, val loss 2.6900\nstep 4000: train loss 2.6019, val loss 2.6751\nstep 5000: train loss 2.5957, val loss 2.6610\nstep 5999: train loss 2.5628, val loss 2.6468\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sft(12000, 2000)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T15:51:54.849160Z","iopub.execute_input":"2024-06-09T15:51:54.849586Z","iopub.status.idle":"2024-06-09T17:30:58.027294Z","shell.execute_reply.started":"2024-06-09T15:51:54.849526Z","shell.execute_reply":"2024-06-09T17:30:58.026262Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"step 0: train loss 2.5861, val loss 2.6568\nstep 2000: train loss 2.5430, val loss 2.6298\nstep 4000: train loss 2.5724, val loss 2.6216\nstep 6000: train loss 2.5560, val loss 2.6032\nstep 8000: train loss 2.5307, val loss 2.5827\nstep 10000: train loss 2.5076, val loss 2.5574\nstep 11999: train loss 2.5006, val loss 2.5719\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sft(6000, 1000)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:40:31.431641Z","iopub.execute_input":"2024-06-09T18:40:31.431992Z","iopub.status.idle":"2024-06-09T19:33:39.249352Z","shell.execute_reply.started":"2024-06-09T18:40:31.431964Z","shell.execute_reply":"2024-06-09T19:33:39.248170Z"},"trusted":true},"execution_count":210,"outputs":[{"name":"stdout","text":"step 0: train loss 2.4938, val loss 2.5556\nstep 1000: train loss 2.5002, val loss 2.5623\nstep 2000: train loss 2.4909, val loss 2.5637\nstep 3000: train loss 2.4754, val loss 2.5444\nstep 4000: train loss 2.4698, val loss 2.5463\nstep 5000: train loss 2.4739, val loss 2.5401\nstep 5999: train loss 2.4515, val loss 2.5342\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sft(6000, 1000)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:47:55.778300Z","iopub.execute_input":"2024-06-09T19:47:55.779303Z","iopub.status.idle":"2024-06-09T20:41:11.387796Z","shell.execute_reply.started":"2024-06-09T19:47:55.779260Z","shell.execute_reply":"2024-06-09T20:41:11.386750Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"step 0: train loss 2.4679, val loss 2.5351\nstep 1000: train loss 2.4776, val loss 2.5460\nstep 2000: train loss 2.4722, val loss 2.5502\nstep 3000: train loss 2.4588, val loss 2.5342\nstep 4000: train loss 2.4548, val loss 2.5346\nstep 5000: train loss 2.4625, val loss 2.5330\nstep 5999: train loss 2.4387, val loss 2.5248\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sft(3000, 1000)\nsave_model() ","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:49:56.319758Z","iopub.execute_input":"2024-06-12T11:49:56.320777Z","iopub.status.idle":"2024-06-12T12:17:14.849414Z","shell.execute_reply.started":"2024-06-12T11:49:56.320734Z","shell.execute_reply":"2024-06-12T12:17:14.848418Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"step 0: train loss 2.4455, val loss 2.5953\nstep 1000: train loss 2.4013, val loss 2.5249\nstep 2000: train loss 2.3865, val loss 2.5351\nstep 2999: train loss 2.4326, val loss 2.5251\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sft(3000, 500)\nsave_model() ","metadata":{"execution":{"iopub.status.busy":"2024-06-12T21:53:28.328892Z","iopub.execute_input":"2024-06-12T21:53:28.329265Z","iopub.status.idle":"2024-06-12T22:23:55.114144Z","shell.execute_reply.started":"2024-06-12T21:53:28.329236Z","shell.execute_reply":"2024-06-12T22:23:55.113139Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"step 0: train loss 2.4549, val loss 2.5201\nstep 500: train loss 2.4551, val loss 2.5329\nstep 1000: train loss 2.4476, val loss 2.5122\nstep 1500: train loss 2.4499, val loss 2.5074\nstep 2000: train loss 2.4429, val loss 2.5076\nstep 2500: train loss 2.4372, val loss 2.5180\nstep 2999: train loss 2.4309, val loss 2.5189\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sft(3000, 1000)\nsave_model() ","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:49:55.983711Z","iopub.execute_input":"2024-06-12T22:49:55.983983Z","iopub.status.idle":"2024-06-12T23:17:02.371926Z","shell.execute_reply.started":"2024-06-12T22:49:55.983959Z","shell.execute_reply":"2024-06-12T23:17:02.370927Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"step 0: train loss 2.4384, val loss 2.5026\nstep 1000: train loss 2.3664, val loss 2.5247\nstep 2000: train loss 2.4311, val loss 2.5013\nstep 2999: train loss 2.3775, val loss 2.5006\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sft(3000, 1000)\nsave_model() ","metadata":{"execution":{"iopub.status.busy":"2024-06-13T01:49:48.203750Z","iopub.execute_input":"2024-06-13T01:49:48.204125Z","iopub.status.idle":"2024-06-13T02:17:06.411611Z","shell.execute_reply.started":"2024-06-13T01:49:48.204095Z","shell.execute_reply":"2024-06-13T02:17:06.410618Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"step 0: train loss 2.4056, val loss 2.5406\nstep 1000: train loss 2.3866, val loss 2.4915\nstep 2000: train loss 2.3629, val loss 2.5062\nstep 2999: train loss 2.4023, val loss 2.4992\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sft(16000, 3000)\nsave_model() ","metadata":{"execution":{"iopub.status.busy":"2024-06-13T02:19:44.347356Z","iopub.execute_input":"2024-06-13T02:19:44.347725Z","iopub.status.idle":"2024-06-13T04:30:27.245154Z","shell.execute_reply.started":"2024-06-13T02:19:44.347696Z","shell.execute_reply":"2024-06-13T04:30:27.244052Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"step 0: train loss 2.4024, val loss 2.5084\nstep 3000: train loss 2.3941, val loss 2.4819\nstep 6000: train loss 2.4046, val loss 2.4790\nstep 9000: train loss 2.3782, val loss 2.4671\nstep 12000: train loss 2.3592, val loss 2.4554\nstep 15000: train loss 2.3769, val loss 2.4657\nstep 15999: train loss 2.3654, val loss 2.4427\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sft(5000, 1000)\nsave_model() ","metadata":{"execution":{"iopub.status.idle":"2024-06-13T11:30:58.180086Z","shell.execute_reply.started":"2024-06-13T10:46:13.560490Z","shell.execute_reply":"2024-06-13T11:30:58.179050Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"step 1000: train loss 2.3655, val loss 2.4621\nstep 2000: train loss 2.3637, val loss 2.4672\nstep 3000: train loss 2.3622, val loss 2.4544\nstep 4000: train loss 2.3309, val loss 2.4499\nstep 4999: train loss 2.3446, val loss 2.4540\n","output_type":"stream"}]},{"cell_type":"code","source":"generate(1024, user_prompt='Write a comprehensive blog post of at least 1000 words about the top 10 most eco-friendly cities in the world and their renewable energy initiatives.', chat_template=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:46:28.635964Z","iopub.execute_input":"2024-06-14T13:46:28.636281Z","iopub.status.idle":"2024-06-14T13:46:48.315148Z","shell.execute_reply.started":"2024-06-14T13:46:28.636255Z","shell.execute_reply":"2024-06-14T13:46:48.313975Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\nComprehensively reviewing and promoting the National Renewable, Renewable Energy System (NREL) development programs for federal, state, and local communities can take a competitive approach, take customer satisfaction surveys, and demonstrate the duty of investments in the Flexible, Wind, Public Transit Industry.\n\nIn this post, we will explore various sustainable cities and their renewable energy initiatives, provide recommendations for sustainable development, and address the need for fuel, public transport, subsidies, Electroc, and other incentives to encourage and support the program. We will design and implement policies and practices that promote renewable energy for major waterways and address common challenges.\n\nBenefits: Advertising in the Green Business Neighborhood Service include:\n\n1. Cost Savings\n2. Environmental Cost\n3. Reducing greenhouse gas emissions and energy consumption\n4. Energy Use Extensive Maintenance\n5. Boosts an efficient utilization of carbon emissions\n   D2 = 4%. Motive higher energy consumption, than those made from fossil fuels.\n\nConsultions: Graphics concerning climate change can be a long and lonely road where planners are planning to gather these resources efficiently and implement policies that increase efficiency, reducing greenhouse gas emissions, and more natural resources donations to be wasted.\n\nComparatives of Second, Theme Zones\n\n1. Renewable Portfolio Standards (JESZones)\n- Mellon models: Several wind turbines and geothermal systems have demonstrated PEVs in an attractive light, Use-Flo (DUT) and LED designs for in- AAA applications.\n- Improvements to existing transportation systems might reduce the amount of greenhouse gas emissions between single and species types in the green business model provided on land, while cutting do-edge processes for rain: offshore wind turbines, gas turbines, and air contrast are unavailable.\n- American Renewable Portuses (ETS) provide a sorted survey that predicts the economic impact of greenhouse gas emissions. Studies could show that Eurolines is environmentally friendly alternatives because coal contrasting pathogens such as non-numeric and non-carbon.\n- Alaminates: America plans to reduce greenhouse gas emissions by combining all possible generalized traffic countdown similar to a drop-down underrepresented nodes to reduce reliance, and switch to lower greenhouse gas emissions.\n\nBest Practices for Implementing Local Governance:\n\n1. Leading by example: Many cities are reacting to wastewater emits greenhouse gas emissions recharged and non-carbon dioxide (PECSA) from emerging sources, such as coal and gas (GHSA).\n- Martin Lutherbachs: President Raymond, Joseph Jonathan Ramblin, a singer from China who areXf tours into the Union Square, all released from profession- recommendations available on mass data for severalates and separated rivers, gas generators, and craft denials.\n- Shay Hinton: Malachi is another polymath, with the strongest numbers in recent years. He is a former president of Manifest Destiny, and by 1973, the Spanish President James K. And Pierre Wintwaugh earned an Red Bull Park Award from the Federal Ministry of Agriculture with honors from Jamaica Mass.\n- Marcia Waldichloin: Temporal Commentary on Inc.\n- Harvard Business Review: On Thu Jan, January 28, 2013, and dripping with greenhouse gas emissions from occurring and mixed news with an \"measured one billion-strung broccoli\"), with another unemployed writer Unleoyment Partners (KADS) suggesting.\n\nI hope these tips are helpful to help you conduct thorough research and uncover the ways to optimize our HIIT collection of scientific articles!\n","output_type":"stream"}]}]}