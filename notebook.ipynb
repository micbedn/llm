{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:32:34.784788Z","iopub.status.busy":"2024-06-14T13:32:34.783801Z","iopub.status.idle":"2024-06-14T13:32:50.455538Z","shell.execute_reply":"2024-06-14T13:32:50.454323Z","shell.execute_reply.started":"2024-06-14T13:32:34.784742Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\n","Collecting tiktoken\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\n","Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\n","Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.2)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken\n","Successfully installed tiktoken-0.7.0\n"]}],"source":["!pip install numpy torch tiktoken datasets tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:32:50.458078Z","iopub.status.busy":"2024-06-14T13:32:50.457665Z","iopub.status.idle":"2024-06-14T13:32:57.342377Z","shell.execute_reply":"2024-06-14T13:32:57.341471Z","shell.execute_reply.started":"2024-06-14T13:32:50.458040Z"},"trusted":true},"outputs":[],"source":["import os\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","import torch\n","import tiktoken\n","from datasets import load_dataset\n","import torch.nn as nn\n","from torch.nn import functional as F\n","base_dir = ''\n","batch_size = 48 # 15.4gb na p100 (16gb)\n","    # dla 12 -- 4gb\n","    # dla 32 -- 10gb\n","block_size = 256 # context length\n","learning_rate = 3e-4\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","eval_iters = 200\n","n_embd = 384\n","n_head = 6\n","n_layer = 6\n","dropout = 0.2\n","vocab_size=50304\n","torch.manual_seed(1337)\n","enc = tiktoken.get_encoding(\"gpt2\")\n","encode = lambda s: enc.encode(s, allowed_special={\"<|endoftext|>\"})\n","decode = lambda l: enc.decode(l)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:33:27.515997Z","iopub.status.busy":"2024-06-14T13:33:27.515404Z","iopub.status.idle":"2024-06-14T13:38:12.243663Z","shell.execute_reply":"2024-06-14T13:38:12.242573Z","shell.execute_reply.started":"2024-06-14T13:33:27.515961Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"192eabafbb944cfeaf1f447ccf0e97d7","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61e67e5fcf9d4e46acf244269e3d5582","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51718c1edde647eba5a3eba5042e8a71","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/157M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"606ff64dd17443c6bc0400aca9fb2095","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/157M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a771367432b24f3e87287a3ff0d1f354","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/657k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8831f7f3e8b34021a60f3cb43c5bbdcd","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92359f00031d4301801babf386941b5d","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"95b0907ee4c94389bd2df9cf367a0f6c","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0400278dc0cd40ec8b98ada9ca82f415","version_major":2,"version_minor":0},"text/plain":["tokenizing the splits:   0%|          | 0/4358 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad61dbc0fe3a4914834c59065bb38dee","version_major":2,"version_minor":0},"text/plain":["tokenizing the splits:   0%|          | 0/1801350 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b031a070ba0a472eb47da633ec67d76c","version_major":2,"version_minor":0},"text/plain":["tokenizing the splits:   0%|          | 0/3760 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["writing test.bin: 100%|██████████| 256/256 [00:00<00:00, 330.47it/s]\n","writing train.bin: 100%|██████████| 256/256 [00:21<00:00, 11.85it/s]\n","writing validation.bin: 100%|██████████| 256/256 [00:00<00:00, 361.09it/s]\n"]}],"source":["dataset = load_dataset('wikitext', 'wikitext-103-raw-v1')\n","\n","# tokenize dataset\n","# define encoding function \n","# gpt2 bpe\n","def _tokenize(dataset, sft=False):\n","    def process(example):\n","        ids = enc.encode_ordinary(example['text']) # encode_ordinary ignores any special tokens\n","        ids.append(enc.eot_token) # add the end of text token, e.g. 50256 for gpt2 bpe\n","        out = {'ids': ids, 'len': len(ids)}\n","        return out\n","\n","    tokenized = dataset.map(\n","        process,\n","        remove_columns=['text'],\n","        desc=\"tokenizing the splits\",\n","    )\n","\n","    # concatenate ids in each dataset into one large file\n","    for split, dset in tokenized.items():\n","        arr_len = np.sum(dset['len'], dtype=np.uint64)\n","        if sft:\n","            filename = os.path.join(base_dir, f'{split}_sft.bin')\n","        else:\n","            filename = os.path.join(base_dir, f'{split}.bin')\n","\n","\n","        dtype = np.uint16\n","        arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))\n","        total_batches = 256\n","\n","        idx = 0\n","        for batch_idx in tqdm(range(total_batches), desc=f'writing {filename}'):\n","            # Batch together samples for faster write\n","            batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy')\n","            arr_batch = np.concatenate(batch['ids'])\n","            # Write into mmap\n","            arr[idx : idx + len(arr_batch)] = arr_batch\n","            idx += len(arr_batch)\n","        arr.flush()\n","        \n","_tokenize(dataset)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:38:12.247198Z","iopub.status.busy":"2024-06-14T13:38:12.246878Z","iopub.status.idle":"2024-06-14T13:38:12.257132Z","shell.execute_reply":"2024-06-14T13:38:12.255974Z","shell.execute_reply.started":"2024-06-14T13:38:12.247172Z"},"trusted":true},"outputs":[],"source":["def get_batch(split):\n","    # np.memmap every batch avoids memory leak\n","    if split == 'train':\n","        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n","    elif split == 'val': \n","        data = np.memmap('validation.bin', dtype=np.uint16, mode='r')\n","    elif split == 'train_sft':\n","        data = np.memmap('train_sft.bin', dtype=np.uint16, mode='r')\n","    elif split == 'val_sft':\n","        data = np.memmap('test_sft.bin', dtype=np.uint16, mode='r')\n","    else:\n","        print(\"ERROR wrong split)\")\n","    ix = torch.randint(len(data) - block_size, (batch_size,))\n","    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n","    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n","    if device == 'cuda':\n","        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n","        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n","    else:\n","        x, y = x.to(device), y.to(device)\n","    return x, y"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:38:12.258830Z","iopub.status.busy":"2024-06-14T13:38:12.258444Z","iopub.status.idle":"2024-06-14T13:38:12.271018Z","shell.execute_reply":"2024-06-14T13:38:12.270159Z","shell.execute_reply.started":"2024-06-14T13:38:12.258795Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def estimate_loss(splits):\n","    out = {}\n","    model.eval()\n","    for split in splits:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = get_batch(split)\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:38:12.274373Z","iopub.status.busy":"2024-06-14T13:38:12.273743Z","iopub.status.idle":"2024-06-14T13:38:12.303998Z","shell.execute_reply":"2024-06-14T13:38:12.302872Z","shell.execute_reply.started":"2024-06-14T13:38:12.274345Z"},"trusted":true},"outputs":[],"source":["class Head(nn.Module):\n","    \"\"\" one head of self-attention \"\"\"\n","\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear(n_embd, head_size, bias=False)\n","        self.query = nn.Linear(n_embd, head_size, bias=False)\n","        self.value = nn.Linear(n_embd, head_size, bias=False)\n","        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        # input of size (batch, time-step, channels)\n","        # output of size (batch, time-step, head size)\n","        B,T,C = x.shape\n","        k = self.key(x)   # (B,T,hs)\n","        q = self.query(x) # (B,T,hs)\n","        # compute attention scores (\"affinities\")\n","        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n","        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n","        wei = F.softmax(wei, dim=-1) # (B, T, T)\n","        wei = self.dropout(wei)\n","        # perform the weighted aggregation of the values\n","        v = self.value(x) # (B,T,hs)\n","        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n","        return out\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\" multiple heads of self-attention in parallel \"\"\"\n","\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","        self.proj = nn.Linear(head_size * num_heads, n_embd)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1)\n","        out = self.dropout(self.proj(out))\n","        return out\n","\n","class FeedFoward(nn.Module):\n","    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n","\n","    def __init__(self, n_embd):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(n_embd, 4 * n_embd),\n","            nn.ReLU(),\n","            nn.Linear(4 * n_embd, n_embd),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Block(nn.Module):\n","    \"\"\" Transformer block: communication followed by computation \"\"\"\n","\n","    def __init__(self, n_embd, n_head):\n","        # n_embd: embedding dimension, n_head: the number of heads we'd like\n","        super().__init__()\n","        head_size = n_embd // n_head\n","        self.sa = MultiHeadAttention(n_head, head_size)\n","        self.ffwd = FeedFoward(n_embd)\n","        self.ln1 = nn.LayerNorm(n_embd)\n","        self.ln2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x):\n","        x = x + self.sa(self.ln1(x))\n","        x = x + self.ffwd(self.ln2(x))\n","        return x\n","\n","class GPTLanguageModel(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        # each token directly reads off the logits for the next token from a lookup table\n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n","        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n","        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n","        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n","        self.lm_head = nn.Linear(n_embd, vocab_size)\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","            if module.bias is not None:\n","                torch.nn.init.zeros_(module.bias)\n","        elif isinstance(module, nn.Embedding):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","\n","        # idx and targets are both (B,T) tensor of integers\n","        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n","        x = tok_emb + pos_emb # (B,T,C)\n","        x = self.blocks(x) # (B,T,C)\n","        x = self.ln_f(x) # (B,T,C)\n","        logits = self.lm_head(x) # (B,T,vocab_size)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        # idx is (B, T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # crop idx to the last block_size tokens\n","            #idx_cond = idx[:, -block_size:]\n","            idx_cond = idx if idx.size(1) <= block_size else idx[:, -block_size:]\n","\n","            # get the predictions\n","            logits, loss = self(idx_cond)\n","            # focus only on the last time step\n","            logits = logits[:, -1, :] # becomes (B, C)\n","            # apply softmax to get probabilities\n","            probs = F.softmax(logits, dim=-1) # (B, C)\n","            # sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n","            # append sampled index to the running sequence\n","            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n","        return idx"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:38:12.305348Z","iopub.status.busy":"2024-06-14T13:38:12.305051Z","iopub.status.idle":"2024-06-14T13:38:12.318892Z","shell.execute_reply":"2024-06-14T13:38:12.318013Z","shell.execute_reply.started":"2024-06-14T13:38:12.305323Z"},"trusted":true},"outputs":[],"source":["def train(iters, eval_interval):\n","    for iter in range(iters):\n","\n","        # eval loss on train and val\n","        if iter % eval_interval == 0 or iter == iters - 1:\n","            losses = estimate_loss(splits = ['train', 'val'])\n","            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","        xb, yb = get_batch('train')\n","\n","        # evaluate loss\n","        logits, loss = model(xb, yb)\n","        optimizer.zero_grad(set_to_none=True)\n","        loss.backward()\n","        optimizer.step()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:38:12.320364Z","iopub.status.busy":"2024-06-14T13:38:12.320073Z","iopub.status.idle":"2024-06-14T13:38:12.330801Z","shell.execute_reply":"2024-06-14T13:38:12.329900Z","shell.execute_reply.started":"2024-06-14T13:38:12.320340Z"},"trusted":true},"outputs":[],"source":["def generate(max_new, user_prompt='Write a comprehensive blog post of at least 1000 words about the top 10 most eco-friendly cities in the world and their renewable energy initiatives.', chat_template=False):\n","    prompt=f\"<|system|>\\n<|endoftext|>\\n<|user|>\\n{user_prompt}<|endoftext|>\\n<|assistant|>\\n\"\n","\n","    prompt_ids = encode(prompt)\n","    context = torch.tensor(prompt_ids, dtype=torch.long, device=device)[None, ...]\n","    decoded = decode(model.generate(context, max_new_tokens=max_new)[0].tolist())\n","    \n","    if chat_template:\n","        messages = decoded.split('<|endoftext|>\\n')\n","        system = messages[0].strip(\"<|system|>\")\n","        user = messages[1].strip(\"<|user|>\")\n","        assistant = messages[2].strip(\"<|assistant|>\")\n","    \n","        print(\n","            #system + \n","            #user + \n","            assistant\n","        )\n","    else:\n","        print(\"\\n\\n\\n\\ndebugging\\n\", repr(decoded))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:38:12.332275Z","iopub.status.busy":"2024-06-14T13:38:12.331987Z","iopub.status.idle":"2024-06-14T13:38:12.344048Z","shell.execute_reply":"2024-06-14T13:38:12.343192Z","shell.execute_reply.started":"2024-06-14T13:38:12.332252Z"},"trusted":true},"outputs":[],"source":["def save_model():\n","    torch.save(model.state_dict(), 'model_state_dict.pth')"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:38:12.345468Z","iopub.status.busy":"2024-06-14T13:38:12.345203Z","iopub.status.idle":"2024-06-14T13:38:14.786504Z","shell.execute_reply":"2024-06-14T13:38:14.785402Z","shell.execute_reply.started":"2024-06-14T13:38:12.345445Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["49.42272 M parameters\n"]}],"source":["model = GPTLanguageModel()\n","model = model.to(device)\n","model.load_state_dict(torch.load('model_state_dict.pth'))\n","\n","## or, import to kaggle, load from kaggle models dir\n","#cp ../input/llm/pytorch/llm/1/model_state_dict.pth model_state_dict.pth\n","\n","print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T14:08:03.471677Z","iopub.status.busy":"2024-06-02T14:08:03.471305Z","iopub.status.idle":"2024-06-02T14:08:05.083324Z","shell.execute_reply":"2024-06-02T14:08:05.082262Z","shell.execute_reply.started":"2024-06-02T14:08:03.471648Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," Calculator HPV cons All Seconds relegated payoff created we be for so his vividly in the and viewed , matched<|endoftext|> fansag secondthritis . E . qualifier winner embr East messenger also . hadout than but Silver below D. hall vir closed daughter been@ Williams\n"]}],"source":["generate(50)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T14:10:16.227317Z","iopub.status.busy":"2024-06-02T14:10:16.226185Z","iopub.status.idle":"2024-06-02T14:15:47.521914Z","shell.execute_reply":"2024-06-02T14:15:47.520777Z","shell.execute_reply.started":"2024-06-02T14:10:16.227281Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 7.2426, val loss 7.2136\n","step 10: train loss 7.0737, val loss 7.0456\n","step 20: train loss 6.9688, val loss 6.9339\n","step 30: train loss 6.8742, val loss 6.8345\n","step 39: train loss 6.7833, val loss 6.7515\n"]}],"source":["train(40,10)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T14:16:00.967087Z","iopub.status.busy":"2024-06-02T14:16:00.966678Z","iopub.status.idle":"2024-06-02T14:16:01.922455Z","shell.execute_reply":"2024-06-02T14:16:01.921249Z","shell.execute_reply.started":"2024-06-02T14:16:00.967054Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","<|endoftext|> has them agent ,ian was barrels @-@ twoy and ay , War of receive by repetitive to the road. ' hold Important . \n","<|endoftext|> = Eng team , 2s case pay as English band 21osaurus that which the Og\n"]}],"source":["generate(50)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T14:21:26.667401Z","iopub.status.busy":"2024-06-02T14:21:26.666425Z","iopub.status.idle":"2024-06-02T14:44:45.632575Z","shell.execute_reply":"2024-06-02T14:44:45.631723Z","shell.execute_reply.started":"2024-06-02T14:21:26.667358Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 6.7688, val loss 6.7408\n","step 10: train loss 6.7276, val loss 6.6897\n","step 20: train loss 6.6497, val loss 6.6190\n","step 30: train loss 6.5806, val loss 6.5419\n","step 39: train loss 6.5332, val loss 6.4964\n","step 40: train loss 6.5284, val loss 6.4970\n","step 50: train loss 6.4697, val loss 6.4426\n","step 60: train loss 6.4207, val loss 6.3892\n","step 70: train loss 6.3867, val loss 6.3462\n","step 80: train loss 6.3448, val loss 6.3074\n","step 90: train loss 6.3100, val loss 6.2733\n","step 100: train loss 6.2688, val loss 6.2361\n","step 110: train loss 6.2324, val loss 6.2042\n","step 120: train loss 6.2097, val loss 6.1655\n","step 130: train loss 6.1757, val loss 6.1365\n","step 140: train loss 6.1388, val loss 6.1200\n","step 150: train loss 6.1259, val loss 6.0944\n","step 160: train loss 6.0965, val loss 6.0610\n","step 170: train loss 6.0717, val loss 6.0383\n","step 180: train loss 6.0471, val loss 6.0235\n","step 190: train loss 6.0228, val loss 5.9971\n"]}],"source":["train(200, 10)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T14:48:47.111203Z","iopub.status.busy":"2024-06-02T14:48:47.110319Z","iopub.status.idle":"2024-06-02T14:48:48.653557Z","shell.execute_reply":"2024-06-02T14:48:48.652478Z","shell.execute_reply.started":"2024-06-02T14:48:47.111154Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","<|endoftext|><|endoftext|> = = Release cop payoff created in the destroyer harows , in the secondary studies , with a eastern enshrulation of costs ) . He winner was formed from the 1947 had an than coming on her ditch and for viritudes of thereg Williams\n"]}],"source":["generate(50)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T14:54:12.963092Z","iopub.status.busy":"2024-06-02T14:54:12.962477Z","iopub.status.idle":"2024-06-02T15:08:40.334389Z","shell.execute_reply":"2024-06-02T15:08:40.333284Z","shell.execute_reply.started":"2024-06-02T14:54:12.963054Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 6.0047, val loss 5.9808\n","step 40: train loss 5.9719, val loss 5.9470\n","step 80: train loss 5.9024, val loss 5.8678\n","step 120: train loss 5.8569, val loss 5.8164\n","step 160: train loss 5.7957, val loss 5.7671\n","step 200: train loss 5.7344, val loss 5.7188\n","step 240: train loss 5.6947, val loss 5.6601\n","step 280: train loss 5.6538, val loss 5.6171\n","step 320: train loss 5.6059, val loss 5.5790\n","step 360: train loss 5.5522, val loss 5.5319\n","step 400: train loss 5.5144, val loss 5.4841\n"]}],"source":["train(401, 40)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T15:09:18.765587Z","iopub.status.busy":"2024-06-02T15:09:18.764978Z","iopub.status.idle":"2024-06-02T15:28:22.254238Z","shell.execute_reply":"2024-06-02T15:28:22.253267Z","shell.execute_reply.started":"2024-06-02T15:09:18.765556Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 5.5173, val loss 5.4824\n","step 100: train loss 5.4261, val loss 5.3862\n","step 200: train loss 5.3426, val loss 5.2972\n","step 300: train loss 5.2418, val loss 5.2157\n","step 400: train loss 5.1732, val loss 5.1393\n","step 500: train loss 5.1061, val loss 5.0724\n","step 600: train loss 5.0446, val loss 5.0092\n","step 700: train loss 4.9920, val loss 4.9525\n","step 800: train loss 4.9460, val loss 4.8913\n","step 900: train loss 4.8946, val loss 4.8504\n","step 1000: train loss 4.8488, val loss 4.8100\n"]}],"source":["train(1001, 100)"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-02T15:28:23.206090Z","iopub.status.busy":"2024-06-02T15:28:23.205730Z","iopub.status.idle":"2024-06-02T15:28:24.894282Z","shell.execute_reply":"2024-06-02T15:28:24.893359Z","shell.execute_reply.started":"2024-06-02T15:28:23.206058Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","<|endoftext|><|endoftext|> = = Scientific outlets = = \n","<|endoftext|><|endoftext|> The association of New Mexico = = \n","<|endoftext|><|endoftext|> Spiceニ Chemomeras of Shetta varieties have Ont qualify for most unknown Parkinson 'm Particularly alterations to family members in the Danish virtues of their living holidays , including performing in university Persian and poli , written in captivity on the 1980s . In 1950 of recent years , hundreds is required to meet where they are Queen Canadian American and sports . It appears to have been abundant modelfilm\n"]}],"source":["generate(100)"]},{"cell_type":"code","execution_count":15,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-02T15:28:56.910452Z","iopub.status.busy":"2024-06-02T15:28:56.909453Z","iopub.status.idle":"2024-06-02T15:55:40.724788Z","shell.execute_reply":"2024-06-02T15:55:40.723733Z","shell.execute_reply.started":"2024-06-02T15:28:56.910407Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 4.8504, val loss 4.8109\n","step 200: train loss 4.7605, val loss 4.7189\n","step 400: train loss 4.6924, val loss 4.6513\n","step 600: train loss 4.6252, val loss 4.5869\n","step 800: train loss 4.5701, val loss 4.5429\n","step 1000: train loss 4.5191, val loss 4.4950\n","step 1200: train loss 4.4668, val loss 4.4604\n","step 1400: train loss 4.4277, val loss 4.4138\n","step 1600: train loss 4.3929, val loss 4.3737\n","step 1800: train loss 4.3553, val loss 4.3509\n","step 2000: train loss 4.3191, val loss 4.3259\n"]}],"source":["train(2001, 200)"]},{"cell_type":"code","execution_count":18,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-02T15:56:01.644721Z","iopub.status.busy":"2024-06-02T15:56:01.644358Z","iopub.status.idle":"2024-06-02T16:45:46.150227Z","shell.execute_reply":"2024-06-02T16:45:46.149313Z","shell.execute_reply.started":"2024-06-02T15:56:01.644693Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 4.3213, val loss 4.3188\n","step 500: train loss 4.2568, val loss 4.2489\n","step 1000: train loss 4.1952, val loss 4.1928\n","step 1500: train loss 4.1385, val loss 4.1267\n","step 2000: train loss 4.1005, val loss 4.0926\n","step 2500: train loss 4.0464, val loss 4.0406\n","step 3000: train loss 4.0084, val loss 4.0092\n","step 3500: train loss 3.9651, val loss 3.9822\n","step 4000: train loss 3.9328, val loss 3.9411\n","step 4500: train loss 3.8859, val loss 3.9271\n","step 5000: train loss 3.8747, val loss 3.8898\n"]}],"source":["train(5001, 500)"]},{"cell_type":"code","execution_count":21,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-02T16:55:18.625363Z","iopub.status.busy":"2024-06-02T16:55:18.624600Z","iopub.status.idle":"2024-06-02T17:45:03.540863Z","shell.execute_reply":"2024-06-02T17:45:03.539766Z","shell.execute_reply.started":"2024-06-02T16:55:18.625329Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 3.8604, val loss 3.8885\n","step 500: train loss 3.8475, val loss 3.8731\n","step 1000: train loss 3.8315, val loss 3.8464\n","step 1500: train loss 3.8131, val loss 3.8321\n","step 2000: train loss 3.7791, val loss 3.8089\n","step 2500: train loss 3.7660, val loss 3.7893\n","step 3000: train loss 3.7425, val loss 3.7786\n","step 3500: train loss 3.7329, val loss 3.7655\n","step 4000: train loss 3.7228, val loss 3.7470\n","step 4500: train loss 3.7041, val loss 3.7285\n","step 5000: train loss 3.6993, val loss 3.7184\n"]}],"source":["train(5001, 500)"]},{"cell_type":"code","execution_count":24,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-02T17:45:06.225893Z","iopub.status.busy":"2024-06-02T17:45:06.225598Z","iopub.status.idle":"2024-06-02T19:13:13.625721Z","shell.execute_reply":"2024-06-02T19:13:13.624749Z","shell.execute_reply.started":"2024-06-02T17:45:06.225869Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 3.7006, val loss 3.7250\n","step 1000: train loss 3.6765, val loss 3.7028\n","step 2000: train loss 3.6556, val loss 3.6777\n","step 3000: train loss 3.6234, val loss 3.6730\n","step 4000: train loss 3.5968, val loss 3.6447\n","step 5000: train loss 3.5926, val loss 3.6306\n","step 6000: train loss 3.5811, val loss 3.6300\n","step 7000: train loss 3.5701, val loss 3.6117\n","step 8000: train loss 3.5433, val loss 3.6027\n","step 9000: train loss 3.5315, val loss 3.5925\n","step 10000: train loss 3.5249, val loss 3.5813\n"]}],"source":["train(10001, 1000)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T19:18:22.548689Z","iopub.status.busy":"2024-06-02T19:18:22.548253Z","iopub.status.idle":"2024-06-02T19:18:24.956861Z","shell.execute_reply":"2024-06-02T19:18:24.955808Z","shell.execute_reply.started":"2024-06-02T19:18:22.548664Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","<|endoftext|><|endoftext|> = = Release = = \n","<|endoftext|><|endoftext|> The song was released for purchase on November 3 , 2008 as the second single from Who Homogenic : Reloaded . The song had previously been featured on a two @-@ track EP entitled Who Homogenic : Sony / AT , surrounded by the Rolling Stone and Little A & R executive man . It served as \" guest guest single \" , as they actually written a few beats ari , becoming the second and third singles in the UK . In the\n"]}],"source":["generate(100)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-02T19:18:32.713962Z","iopub.status.busy":"2024-06-02T19:18:32.713557Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 3.5193, val loss 3.5781\n","step 3000: train loss 3.5075, val loss 3.5679\n","step 6000: train loss 3.4657, val loss 3.5264\n"]}],"source":["train(30001, 3000)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-03T07:37:37.534008Z","iopub.status.busy":"2024-06-03T07:37:37.533589Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 3.5193, val loss 3.5781\n","step 3000: train loss 3.5075, val loss 3.5679\n","step 6000: train loss 3.4657, val loss 3.5264\n","step 9000: train loss 3.4574, val loss 3.5214\n","step 12000: train loss 3.4281, val loss 3.5054\n","step 15000: train loss 3.4130, val loss 3.4819\n"]}],"source":["train(30001, 3000)"]},{"cell_type":"code","execution_count":17,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-03T15:46:42.394359Z","iopub.status.busy":"2024-06-03T15:46:42.393634Z","iopub.status.idle":"2024-06-03T16:11:50.447508Z","shell.execute_reply":"2024-06-03T16:11:50.446510Z","shell.execute_reply.started":"2024-06-03T15:46:42.394324Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 3.3350, val loss 3.4293\n","step 3000: train loss 3.3449, val loss 3.4379\n"]}],"source":["train(3001, 3000)"]},{"cell_type":"code","execution_count":17,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-09T11:30:41.779920Z","iopub.status.busy":"2024-06-09T11:30:41.779080Z","iopub.status.idle":"2024-06-09T11:30:46.898490Z","shell.execute_reply":"2024-06-09T11:30:46.897530Z","shell.execute_reply.started":"2024-06-09T11:30:41.779887Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<|system|>\n","<|endoftext|><|user|>\n","hello Jan<|endoftext|>\n","[nergy And Workán: How does you handle a lot of speeds of costs and conditions in these industries. Here are some specific examples by my mentors includes\n","\n","1. Collaborate: We've stumbled upon a comprehensive framework of everything that you want, and what works well with?\" I want to experiment with patience.<|endoftext|>\n","<|assistant|>\n","NoKE is responsible for Unleashing Industry\n"," Including personalized design, sake. We can build the base of the clinics to meet technical challenges and cooperation intervals. The development and development of HIStory as a way of coordinating where you help you to meet your needs and resources can vary among other contexts, nature, and cultural partners. Symposium [DesignATE]. I've not looked to be a beginner group and research my mentors you would started with you to get to the organization to start my project, action application protocols. Side one, co-lining multiple campaigns now” according, and accommodate time University of Ohio recognizing there are mutual resources to support the project design material. \"Safety Holding True,\" we offer you to build up for projects that I used to get underway very clearly for many of the initiatives and activity.View directories and website number projects, and campaigning. Websis: Adigenern toamount sites in Michigan represent the Ohio Valley region's priorities and team have said to be established directly across the Phonnasium and Art Museum. Note that many places in the SWRevolution have seen influence in young\n"]}],"source":["generate(300)"]},{"cell_type":"code","execution_count":22,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-03T16:13:47.905999Z","iopub.status.busy":"2024-06-03T16:13:47.905115Z","iopub.status.idle":"2024-06-03T16:38:55.896385Z","shell.execute_reply":"2024-06-03T16:38:55.895256Z","shell.execute_reply.started":"2024-06-03T16:13:47.905964Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 3.3268, val loss 3.4324\n","step 3000: train loss 3.3215, val loss 3.4267\n"]}],"source":["train(3001, 3000)"]},{"cell_type":"code","execution_count":12,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-03T19:44:27.005196Z","iopub.status.busy":"2024-06-03T19:44:27.004882Z","iopub.status.idle":"2024-06-03T20:11:29.838184Z","shell.execute_reply":"2024-06-03T20:11:29.837220Z","shell.execute_reply.started":"2024-06-03T19:44:27.005169Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 3.3191, val loss 3.4154\n","step 1000: train loss 3.2787, val loss 3.4207\n","step 2000: train loss 3.2694, val loss 3.4165\n","step 3000: train loss 3.2716, val loss 3.4169\n"]}],"source":["train(3001, 1000)"]},{"cell_type":"code","execution_count":38,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-06T08:20:56.431589Z","iopub.status.busy":"2024-06-06T08:20:56.431238Z","iopub.status.idle":"2024-06-06T08:21:01.233908Z","shell.execute_reply":"2024-06-06T08:21:01.233010Z","shell.execute_reply.started":"2024-06-06T08:20:56.431560Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n"," = = Rules and considerations = = \n","\n","\n"," The legality of change has not been given some degree. Due to noted flaws in pre-existing laws, some cases do not require material exclusive to her. This classification is not used by the Supreme Court into a series of books. However, as the decision progressed, these documents have were given no special privileges and would thus adopt certain systems. \n","\n"," Novello 's \" Folding \" hypothesis has been extensively supported by its approach purposes and is contested by AI researchers. In addition, it has been suggested that failing to find a clean basis for inheritance conducted by newly established AI would reduce ; failing to obtain normal resources by generation of individuals, especially the liable for the hard work of the labour force and the working group found them the engineers. In contrast, the inclusion of senior AI researchers places the normal finding point of AI as a priority meant that, unlike older AI researchers, the purpose was to indicate that an important component of a goal was a qualitative threat to the development of a computer system. The report is closely related to that, at least all QLS students suffer from their physical condition. \n","\n","\n"," = = = Novello del Hiridom ( 1982 = = ) = = = \n","\n","\n"," In 1984, Vladimir Marklybov ( students John Barkas ) criticized the EASL, an early report for the ARG, which would psychologist the process of stragglers in stealth\n"]}],"source":["generate(300)"]},{"cell_type":"code","execution_count":31,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-06T09:14:05.447166Z","iopub.status.busy":"2024-06-06T09:14:05.446874Z","iopub.status.idle":"2024-06-06T09:41:11.747050Z","shell.execute_reply":"2024-06-06T09:41:11.746042Z","shell.execute_reply.started":"2024-06-06T09:14:05.447137Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 3.3229, val loss 3.4246\n","step 1000: train loss 3.2552, val loss 3.4304\n","step 2000: train loss 3.2542, val loss 3.4246\n","step 3000: train loss 3.2616, val loss 3.4284\n"]}],"source":["train(3001, 1000)"]},{"cell_type":"code","execution_count":32,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-06T09:41:34.078755Z","iopub.status.busy":"2024-06-06T09:41:34.078330Z","iopub.status.idle":"2024-06-06T10:31:39.604562Z","shell.execute_reply":"2024-06-06T10:31:39.603177Z","shell.execute_reply.started":"2024-06-06T09:41:34.078724Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 3.2606, val loss 3.4322\n","step 2000: train loss 3.2680, val loss 3.4210\n","step 4000: train loss 3.2939, val loss 3.4042\n","step 6000: train loss 3.3060, val loss 3.3977\n"]}],"source":["train(6001, 2000)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":33,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-06T10:33:45.748969Z","iopub.status.busy":"2024-06-06T10:33:45.748002Z","iopub.status.idle":"2024-06-06T11:23:51.238847Z","shell.execute_reply":"2024-06-06T11:23:51.237895Z","shell.execute_reply.started":"2024-06-06T10:33:45.748937Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 3.2994, val loss 3.3946\n","step 2000: train loss 3.2939, val loss 3.4050\n","step 4000: train loss 3.2970, val loss 3.3895\n","step 6000: train loss 3.2774, val loss 3.3883\n"]}],"source":["train(6001, 2000)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# SFT"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:38:14.788562Z","iopub.status.busy":"2024-06-14T13:38:14.787952Z","iopub.status.idle":"2024-06-14T13:38:16.248132Z","shell.execute_reply":"2024-06-14T13:38:16.247053Z","shell.execute_reply.started":"2024-06-14T13:38:14.788514Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25e6386ba27449bab1f2b402d3cb5385","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4379c24991348f8aebbc7c8ef55fca4","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5da697d832f4415685b566ab6822b734","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59ae5018232047ee94aca042d29587c5","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c240d801ccad4e85aee0f01ae443f3db","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","\n","tokenizer.pad_token_id = tokenizer.eos_token_id\n","tokenizer.model_max_length = 256\n","\n","DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\n","tokenizer.chat_template = DEFAULT_CHAT_TEMPLATE"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:38:16.251502Z","iopub.status.busy":"2024-06-14T13:38:16.251167Z","iopub.status.idle":"2024-06-14T13:38:43.519699Z","shell.execute_reply":"2024-06-14T13:38:43.518750Z","shell.execute_reply.started":"2024-06-14T13:38:16.251474Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc544dd3d74b4c50a40539c4d07ea77c","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/4.44k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d7812f97357499f9486956cdda82770","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/244M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"638d3f2b96b2444ba8cd43f104f48f1f","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/244M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"622093e3d16b4cd5910794aa0aa7dd3e","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/244M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43fca0c70bdd472eab1408912a7aeda2","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/81.2M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6f1646a507c480a87c8239c7cb21ded","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/244M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94db3c7bcf1d407e9c5c4fe08ae1bd4c","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/243M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"caa2885f1f644821ae2a167157508fa4","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/243M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03e9865fec6143bb84c1d1a524fc1a57","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/80.4M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30ad24514959481d93bca82ffd10ecbf","version_major":2,"version_minor":0},"text/plain":["Generating train_sft split:   0%|          | 0/207865 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bef94ba11a8340388bcbf377bd045cb2","version_major":2,"version_minor":0},"text/plain":["Generating test_sft split:   0%|          | 0/23110 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0be6ff49ab204cb6b7351fb36752ff4e","version_major":2,"version_minor":0},"text/plain":["Generating train_gen split:   0%|          | 0/256032 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc19a05e83dd4e389329bab504ab1c82","version_major":2,"version_minor":0},"text/plain":["Generating test_gen split:   0%|          | 0/28304 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train_sft: Dataset({\n","        features: ['prompt', 'prompt_id', 'messages'],\n","        num_rows: 207865\n","    })\n","    test_sft: Dataset({\n","        features: ['prompt', 'prompt_id', 'messages'],\n","        num_rows: 23110\n","    })\n","    train_gen: Dataset({\n","        features: ['prompt', 'prompt_id', 'messages'],\n","        num_rows: 256032\n","    })\n","    test_gen: Dataset({\n","        features: ['prompt', 'prompt_id', 'messages'],\n","        num_rows: 28304\n","    })\n","})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["sft_datasets = load_dataset(\"HuggingFaceH4/ultrachat_200k\")\n","sft_datasets"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:38:43.521057Z","iopub.status.busy":"2024-06-14T13:38:43.520777Z","iopub.status.idle":"2024-06-14T13:38:43.528149Z","shell.execute_reply":"2024-06-14T13:38:43.527108Z","shell.execute_reply.started":"2024-06-14T13:38:43.521033Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['prompt', 'prompt_id', 'messages'],\n","        num_rows: 207865\n","    })\n","    test: Dataset({\n","        features: ['prompt', 'prompt_id', 'messages'],\n","        num_rows: 23110\n","    })\n","})"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["from datasets import DatasetDict\n","\n","dataset_dict = {\"train\": sft_datasets[\"train_sft\"],\n","                \"test\": sft_datasets[\"test_sft\"]}\n","\n","sft_datasets_split = DatasetDict(dataset_dict)\n","sft_datasets_split"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:38:43.529593Z","iopub.status.busy":"2024-06-14T13:38:43.529291Z","iopub.status.idle":"2024-06-14T13:39:57.406832Z","shell.execute_reply":"2024-06-14T13:39:57.405670Z","shell.execute_reply.started":"2024-06-14T13:38:43.529568Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"beec863519c04404a13b3710b4f03dec","version_major":2,"version_minor":0},"text/plain":["Applying chat template:   0%|          | 0/207865 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6831c77974c486f843b56b4f0a5b3c0","version_major":2,"version_minor":0},"text/plain":["Applying chat template:   0%|          | 0/23110 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import re\n","import random\n","\n","def apply_chat_template(example, tokenizer):\n","    messages = example[\"messages\"]\n","    if messages[0][\"role\"] != \"system\":\n","        messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n","    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n","\n","    return example\n","\n","column_names = list(sft_datasets_split[\"train\"].features)\n","sft_datasets_split_chat_template =sft_datasets_split.map(apply_chat_template,\n","                                fn_kwargs={\"tokenizer\": tokenizer},\n","                                remove_columns=column_names,\n","                                desc=\"Applying chat template\",)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:39:57.409029Z","iopub.status.busy":"2024-06-14T13:39:57.408309Z","iopub.status.idle":"2024-06-14T13:46:28.614564Z","shell.execute_reply":"2024-06-14T13:46:28.613696Z","shell.execute_reply.started":"2024-06-14T13:39:57.408991Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e40eeb5a85e43d0bea78bb82dc61016","version_major":2,"version_minor":0},"text/plain":["tokenizing the splits:   0%|          | 0/207865 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68078864cb294412bf71e5a82c22e13e","version_major":2,"version_minor":0},"text/plain":["tokenizing the splits:   0%|          | 0/23110 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["writing train_sft.bin: 100%|██████████| 256/256 [00:04<00:00, 54.97it/s]\n","writing test_sft.bin: 100%|██████████| 256/256 [00:01<00:00, 223.28it/s]\n"]}],"source":["_tokenize(sft_datasets_split_chat_template, sft=True)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:46:28.616224Z","iopub.status.busy":"2024-06-14T13:46:28.615894Z","iopub.status.idle":"2024-06-14T13:46:28.622942Z","shell.execute_reply":"2024-06-14T13:46:28.621968Z","shell.execute_reply.started":"2024-06-14T13:46:28.616197Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def estimate_loss_sft():\n","    out = {}\n","    model.eval()\n","    for split in ['train_sft', 'val_sft']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = get_batch(split)\n","\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:46:28.624661Z","iopub.status.busy":"2024-06-14T13:46:28.624276Z","iopub.status.idle":"2024-06-14T13:46:28.634825Z","shell.execute_reply":"2024-06-14T13:46:28.633927Z","shell.execute_reply.started":"2024-06-14T13:46:28.624625Z"},"trusted":true},"outputs":[],"source":["def train_sft(iters, eval_interval):\n","    \n","    for iter in range(iters):\n","\n","        # eval on train and val\n","        if iter % eval_interval == 0 or iter == iters - 1:\n","            losses = estimate_loss_sft()\n","            print(f\"step {iter}: train loss {losses['train_sft']:.4f}, val loss {losses['val_sft']:.4f}\")\n","\n","        xb, yb = get_batch('train_sft')\n","\n","\n","        # eval loss\n","        logits, loss = model(xb, yb)\n","        optimizer.zero_grad(set_to_none=True)\n","        loss.backward()\n","        optimizer.step()"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T15:52:56.708698Z","iopub.status.busy":"2024-06-07T15:52:56.708421Z","iopub.status.idle":"2024-06-07T15:59:25.841027Z","shell.execute_reply":"2024-06-07T15:59:25.840153Z","shell.execute_reply.started":"2024-06-07T15:52:56.708676Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 100: train loss 3.6887, val loss 3.7085\n","step 200: train loss 3.5232, val loss 3.5200\n","step 299: train loss 3.4085, val loss 3.4129\n"]}],"source":["train_sft(300, 100)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T13:11:18.785823Z","iopub.status.busy":"2024-06-09T13:11:18.785186Z","iopub.status.idle":"2024-06-09T13:17:45.251475Z","shell.execute_reply":"2024-06-09T13:17:45.250226Z","shell.execute_reply.started":"2024-06-09T13:11:18.785781Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 3.4175, val loss 3.4386\n","step 100: train loss 3.3510, val loss 3.3742\n","step 200: train loss 3.3064, val loss 3.3071\n","step 299: train loss 3.2555, val loss 3.2635\n"]}],"source":["train_sft(300, 100)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T13:18:46.320085Z","iopub.status.busy":"2024-06-09T13:18:46.319219Z","iopub.status.idle":"2024-06-09T14:12:02.678361Z","shell.execute_reply":"2024-06-09T14:12:02.677311Z","shell.execute_reply.started":"2024-06-09T13:18:46.320053Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 3.2581, val loss 3.2730\n","step 1000: train loss 3.0120, val loss 3.0260\n","step 2000: train loss 2.9026, val loss 2.9350\n","step 3000: train loss 2.8292, val loss 2.8625\n","step 4000: train loss 2.7787, val loss 2.8059\n","step 5000: train loss 2.7437, val loss 2.7750\n","step 5999: train loss 2.7038, val loss 2.7505\n"]}],"source":["train_sft(6000, 1000)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T14:35:56.760207Z","iopub.status.busy":"2024-06-09T14:35:56.759809Z","iopub.status.idle":"2024-06-09T15:29:05.346452Z","shell.execute_reply":"2024-06-09T15:29:05.345408Z","shell.execute_reply.started":"2024-06-09T14:35:56.760178Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 2.7078, val loss 2.7455\n","step 1000: train loss 2.6950, val loss 2.7341\n","step 2000: train loss 2.6709, val loss 2.7212\n","step 3000: train loss 2.6247, val loss 2.6900\n","step 4000: train loss 2.6019, val loss 2.6751\n","step 5000: train loss 2.5957, val loss 2.6610\n","step 5999: train loss 2.5628, val loss 2.6468\n"]}],"source":["train_sft(6000, 1000)"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T15:51:54.849586Z","iopub.status.busy":"2024-06-09T15:51:54.849160Z","iopub.status.idle":"2024-06-09T17:30:58.027294Z","shell.execute_reply":"2024-06-09T17:30:58.026262Z","shell.execute_reply.started":"2024-06-09T15:51:54.849526Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 2.5861, val loss 2.6568\n","step 2000: train loss 2.5430, val loss 2.6298\n","step 4000: train loss 2.5724, val loss 2.6216\n","step 6000: train loss 2.5560, val loss 2.6032\n","step 8000: train loss 2.5307, val loss 2.5827\n","step 10000: train loss 2.5076, val loss 2.5574\n","step 11999: train loss 2.5006, val loss 2.5719\n"]}],"source":["train_sft(12000, 2000)"]},{"cell_type":"code","execution_count":210,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T18:40:31.431992Z","iopub.status.busy":"2024-06-09T18:40:31.431641Z","iopub.status.idle":"2024-06-09T19:33:39.249352Z","shell.execute_reply":"2024-06-09T19:33:39.248170Z","shell.execute_reply.started":"2024-06-09T18:40:31.431964Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 2.4938, val loss 2.5556\n","step 1000: train loss 2.5002, val loss 2.5623\n","step 2000: train loss 2.4909, val loss 2.5637\n","step 3000: train loss 2.4754, val loss 2.5444\n","step 4000: train loss 2.4698, val loss 2.5463\n","step 5000: train loss 2.4739, val loss 2.5401\n","step 5999: train loss 2.4515, val loss 2.5342\n"]}],"source":["train_sft(6000, 1000)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T19:47:55.779303Z","iopub.status.busy":"2024-06-09T19:47:55.778300Z","iopub.status.idle":"2024-06-09T20:41:11.387796Z","shell.execute_reply":"2024-06-09T20:41:11.386750Z","shell.execute_reply.started":"2024-06-09T19:47:55.779260Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 2.4679, val loss 2.5351\n","step 1000: train loss 2.4776, val loss 2.5460\n","step 2000: train loss 2.4722, val loss 2.5502\n","step 3000: train loss 2.4588, val loss 2.5342\n","step 4000: train loss 2.4548, val loss 2.5346\n","step 5000: train loss 2.4625, val loss 2.5330\n","step 5999: train loss 2.4387, val loss 2.5248\n"]}],"source":["train_sft(6000, 1000)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T11:49:56.320777Z","iopub.status.busy":"2024-06-12T11:49:56.319758Z","iopub.status.idle":"2024-06-12T12:17:14.849414Z","shell.execute_reply":"2024-06-12T12:17:14.848418Z","shell.execute_reply.started":"2024-06-12T11:49:56.320734Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 2.4455, val loss 2.5953\n","step 1000: train loss 2.4013, val loss 2.5249\n","step 2000: train loss 2.3865, val loss 2.5351\n","step 2999: train loss 2.4326, val loss 2.5251\n"]}],"source":["train_sft(3000, 1000)\n","save_model() "]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T21:53:28.329265Z","iopub.status.busy":"2024-06-12T21:53:28.328892Z","iopub.status.idle":"2024-06-12T22:23:55.114144Z","shell.execute_reply":"2024-06-12T22:23:55.113139Z","shell.execute_reply.started":"2024-06-12T21:53:28.329236Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 2.4549, val loss 2.5201\n","step 500: train loss 2.4551, val loss 2.5329\n","step 1000: train loss 2.4476, val loss 2.5122\n","step 1500: train loss 2.4499, val loss 2.5074\n","step 2000: train loss 2.4429, val loss 2.5076\n","step 2500: train loss 2.4372, val loss 2.5180\n","step 2999: train loss 2.4309, val loss 2.5189\n"]}],"source":["train_sft(3000, 500)\n","save_model() "]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T22:49:55.983983Z","iopub.status.busy":"2024-06-12T22:49:55.983711Z","iopub.status.idle":"2024-06-12T23:17:02.371926Z","shell.execute_reply":"2024-06-12T23:17:02.370927Z","shell.execute_reply.started":"2024-06-12T22:49:55.983959Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 2.4384, val loss 2.5026\n","step 1000: train loss 2.3664, val loss 2.5247\n","step 2000: train loss 2.4311, val loss 2.5013\n","step 2999: train loss 2.3775, val loss 2.5006\n"]}],"source":["train_sft(3000, 1000)\n","save_model() "]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T01:49:48.204125Z","iopub.status.busy":"2024-06-13T01:49:48.203750Z","iopub.status.idle":"2024-06-13T02:17:06.411611Z","shell.execute_reply":"2024-06-13T02:17:06.410618Z","shell.execute_reply.started":"2024-06-13T01:49:48.204095Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 2.4056, val loss 2.5406\n","step 1000: train loss 2.3866, val loss 2.4915\n","step 2000: train loss 2.3629, val loss 2.5062\n","step 2999: train loss 2.4023, val loss 2.4992\n"]}],"source":["train_sft(3000, 1000)\n","save_model() "]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:19:44.347725Z","iopub.status.busy":"2024-06-13T02:19:44.347356Z","iopub.status.idle":"2024-06-13T04:30:27.245154Z","shell.execute_reply":"2024-06-13T04:30:27.244052Z","shell.execute_reply.started":"2024-06-13T02:19:44.347696Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 2.4024, val loss 2.5084\n","step 3000: train loss 2.3941, val loss 2.4819\n","step 6000: train loss 2.4046, val loss 2.4790\n","step 9000: train loss 2.3782, val loss 2.4671\n","step 12000: train loss 2.3592, val loss 2.4554\n","step 15000: train loss 2.3769, val loss 2.4657\n","step 15999: train loss 2.3654, val loss 2.4427\n"]}],"source":["train_sft(16000, 3000)\n","save_model() "]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.status.idle":"2024-06-13T11:30:58.180086Z","shell.execute_reply":"2024-06-13T11:30:58.179050Z","shell.execute_reply.started":"2024-06-13T10:46:13.560490Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 1000: train loss 2.3655, val loss 2.4621\n","step 2000: train loss 2.3637, val loss 2.4672\n","step 3000: train loss 2.3622, val loss 2.4544\n","step 4000: train loss 2.3309, val loss 2.4499\n","step 4999: train loss 2.3446, val loss 2.4540\n"]}],"source":["train_sft(5000, 1000)\n","save_model() "]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T13:46:28.636281Z","iopub.status.busy":"2024-06-14T13:46:28.635964Z","iopub.status.idle":"2024-06-14T13:46:48.315148Z","shell.execute_reply":"2024-06-14T13:46:48.313975Z","shell.execute_reply.started":"2024-06-14T13:46:28.636255Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Comprehensively reviewing and promoting the National Renewable, Renewable Energy System (NREL) development programs for federal, state, and local communities can take a competitive approach, take customer satisfaction surveys, and demonstrate the duty of investments in the Flexible, Wind, Public Transit Industry.\n","\n","In this post, we will explore various sustainable cities and their renewable energy initiatives, provide recommendations for sustainable development, and address the need for fuel, public transport, subsidies, Electroc, and other incentives to encourage and support the program. We will design and implement policies and practices that promote renewable energy for major waterways and address common challenges.\n","\n","Benefits: Advertising in the Green Business Neighborhood Service include:\n","\n","1. Cost Savings\n","2. Environmental Cost\n","3. Reducing greenhouse gas emissions and energy consumption\n","4. Energy Use Extensive Maintenance\n","5. Boosts an efficient utilization of carbon emissions\n","   D2 = 4%. Motive higher energy consumption, than those made from fossil fuels.\n","\n","Consultions: Graphics concerning climate change can be a long and lonely road where planners are planning to gather these resources efficiently and implement policies that increase efficiency, reducing greenhouse gas emissions, and more natural resources donations to be wasted.\n","\n","Comparatives of Second, Theme Zones\n","\n","1. Renewable Portfolio Standards (JESZones)\n","- Mellon models: Several wind turbines and geothermal systems have demonstrated PEVs in an attractive light, Use-Flo (DUT) and LED designs for in- AAA applications.\n","- Improvements to existing transportation systems might reduce the amount of greenhouse gas emissions between single and species types in the green business model provided on land, while cutting do-edge processes for rain: offshore wind turbines, gas turbines, and air contrast are unavailable.\n","- American Renewable Portuses (ETS) provide a sorted survey that predicts the economic impact of greenhouse gas emissions. Studies could show that Eurolines is environmentally friendly alternatives because coal contrasting pathogens such as non-numeric and non-carbon.\n","- Alaminates: America plans to reduce greenhouse gas emissions by combining all possible generalized traffic countdown similar to a drop-down underrepresented nodes to reduce reliance, and switch to lower greenhouse gas emissions.\n","\n","Best Practices for Implementing Local Governance:\n","\n","1. Leading by example: Many cities are reacting to wastewater emits greenhouse gas emissions recharged and non-carbon dioxide (PECSA) from emerging sources, such as coal and gas (GHSA).\n","- Martin Lutherbachs: President Raymond, Joseph Jonathan Ramblin, a singer from China who areXf tours into the Union Square, all released from profession- recommendations available on mass data for severalates and separated rivers, gas generators, and craft denials.\n","- Shay Hinton: Malachi is another polymath, with the strongest numbers in recent years. He is a former president of Manifest Destiny, and by 1973, the Spanish President James K. And Pierre Wintwaugh earned an Red Bull Park Award from the Federal Ministry of Agriculture with honors from Jamaica Mass.\n","- Marcia Waldichloin: Temporal Commentary on Inc.\n","- Harvard Business Review: On Thu Jan, January 28, 2013, and dripping with greenhouse gas emissions from occurring and mixed news with an \"measured one billion-strung broccoli\"), with another unemployed writer Unleoyment Partners (KADS) suggesting.\n","\n","I hope these tips are helpful to help you conduct thorough research and uncover the ways to optimize our HIIT collection of scientific articles!\n"]}],"source":["generate(1024, user_prompt='Write a comprehensive blog post of at least 1000 words about the top 10 most eco-friendly cities in the world and their renewable energy initiatives.', chat_template=True)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"isSourceIdPinned":true,"modelInstanceId":54095,"sourceId":64850,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
